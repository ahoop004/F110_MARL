name: gaplock_wavelet_focused
description: Focused sweep on most impactful hyperparameters for wavelet episodic agent

method: bayes
metric:
  name: car_0/rolling/success_rate
  goal: maximize

project: marl-f110
entity: ahoop004-old-dominion-university

command:
  - ${env}
  - python
  - run_sweep.py
  - --scenario
  - scenarios/v2/gaplock_wavelet.yaml

early_terminate:
  type: hyperband
  min_iter: 300
  max_iter: 1500
  s: 2
  eta: 3

parameters:
  episodes:
    value: 1500

  seed:
    distribution: int_uniform
    min: 0
    max: 999999

  # ===== Exploration Noise (critical for discovery) =====
  agents.car_0.params.exploration_noise:
    distribution: uniform
    min: 0.05
    max: 0.3

  # ===== Learning Rate (most critical) =====
  agents.car_0.params.learning_rate:
    distribution: log_uniform_values
    min: 0.0001
    max: 0.001

  # ===== Loss Weight Balance =====
  # Focus on policy vs auxiliary task balance
  agents.car_0.params.loss_weights.policy:
    distribution: uniform
    min: 0.8
    max: 1.2

  agents.car_0.params.loss_weights.value:
    distribution: uniform
    min: 0.4
    max: 0.6

  agents.car_0.params.loss_weights.reconstruction:
    distribution: uniform
    min: 0.05
    max: 0.2

  agents.car_0.params.loss_weights.forward:
    distribution: uniform
    min: 0.05
    max: 0.2

  # ===== Wavelet Type (key architectural choice) =====
  agents.car_0.params.wavelet.type:
    values: ['identity', 'haar', 'db2']

  # ===== Chunk Overlap =====
  agents.car_0.params.chunk_stride:
    distribution: int_uniform
    min: 10
    max: 15

  # ===== Buffer Size =====
  agents.car_0.params.episodic_buffer.capacity:
    distribution: q_uniform
    min: 500
    max: 1500
    q: 500

  # ===== Selection Mode =====
  agents.car_0.params.episodic_buffer.selection_mode:
    values: ['uniform', 'priority']

  # ===== Encoder Latent Dimension =====
  agents.car_0.params.encoder.latent_dim:
    distribution: q_uniform
    min: 64
    max: 192
    q: 64

  # ===== RNN Type =====
  agents.car_0.params.encoder.rnn.type:
    values: ['lstm', 'rnn']

  # ===== Training Warmup =====
  agents.car_0.params.warmup_chunks:
    distribution: int_uniform
    min: 75
    max: 125

  # ===== Discount Factor =====
  agents.car_0.params.gamma:
    distribution: uniform
    min: 0.99
    max: 0.997
