name: gaplock_sac_sweep
description: SAC hyperparameter sweep - uncomment parameters to add to search

method: bayes
metric:
  name: car_0/rolling/success_rate
  goal: maximize

project: marl-f110
entity: ahoop004-old-dominion-university

command:
  - ${env}
  - python
  - run_sweep.py
  - --scenario
  - scenarios/v2/gaplock_sac.yaml

early_terminate:
  type: hyperband
  min_iter: 300
  max_iter: 1000
  s: 2
  eta: 3

parameters:
  episodes:
    value: 1000

  seed:
    distribution: int_uniform
    min: 0
    max: 999999

  # ============================================================================
  # ACTIVE PARAMETERS - Currently being swept
  # ============================================================================

  # Actor learning rate (discretized)
  agents.car_0.params.lr_actor:
    values: [0.0001, 0.0002, 0.0005, 0.001]

  # Critic learning rate (discretized)
  agents.car_0.params.lr_critic:
    values: [0.0001, 0.0002, 0.0005, 0.001]

  # Temperature parameter (entropy regularization strength, discretized)
  agents.car_0.params.alpha:
    values: [0.1, 0.2, 0.5, 1.0]

  # ============================================================================
  # FIXED PARAMETERS - Using good defaults (uncomment to re-enable sweeping)
  # ============================================================================

  # Target entropy (for automatic temperature tuning)
  # Fixed to -1.0; uncomment to sweep
  # agents.car_0.params.target_entropy:
  #   values: [-2.0, -1.5, -1.0, -0.5]

  # Target network update rate (tau)
  # agents.car_0.params.tau:
  #   values: [0.005, 0.01, 0.02]

  # Automatic entropy tuning
  # agents.car_0.params.auto_alpha:
  #   values: [true, false]

  # ============================================================================
  # ALTERNATIVE CONFIGURATIONS - Continuous ranges
  # ============================================================================

  # CONTINUOUS ACTOR LR
  # agents.car_0.params.lr_actor:
  #   distribution: log_uniform_values
  #   min: 0.0001
  #   max: 0.001

  # CONTINUOUS CRITIC LR
  # agents.car_0.params.lr_critic:
  #   distribution: log_uniform_values
  #   min: 0.0001
  #   max: 0.001

  # CONTINUOUS ALPHA
  # agents.car_0.params.alpha:
  #   distribution: uniform
  #   min: 0.1
  #   max: 1.0

  # CONTINUOUS TARGET ENTROPY
  # agents.car_0.params.target_entropy:
  #   distribution: uniform
  #   min: -2.0
  #   max: -0.5

# ============================================================================
# CURRENT CONFIGURATION SUMMARY
# ============================================================================
# Active parameters: 3 (lr_actor, lr_critic, alpha)
# Search space: 4 × 4 × 4 = 64 combinations
# Fixed in scenario: target_entropy=-1.0, tau=0.005, auto_alpha=true
# ============================================================================
