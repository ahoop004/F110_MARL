name: gaplock_td3_hyperband
description: >
  Bayesian sweep for the gaplock TD3 attacker. Runs the training entrypoint
  directly under wandb so Hyperband early termination can pause/kill runs based
  on the live train/return metric.
method: bayes
project: marl-f110
entity: ahoop004-old-dominion-university
metric:
  name: train/return
  goal: maximize

command:
  - ${env}
  - python
  - -m
  - experiments.main
  - --config
  - scenarios/gaplock_td3.yaml
  - --mode
  - train
  - --wandb
  - --wandb-project
  - marl-f110
  - --wandb-entity
  - ahoop004-old-dominion-university
  - --wandb-group
  - gaplock-td3-hyperband
  - --wandb-tags
  - gaplock
  - td3
  - hyperband

early_terminate:
  type: hyperband
  min_iter: 50         # wait for a bit of signal before pruning
  max_iter: 500        # roughly matches main.train_episodes
  s: 2
  eta: 3

parameters:
  agents:
    parameters:
      car_0:
        parameters:
          algorithm:
            parameters:
              params:
                parameters:
                  actor_lr:
                    values: [0.0004, 0.0008, 0.0015, 0.003, 0.004]
                  critic_lr:
                    values: [0.0004, 0.0008, 0.0015, 0.003, 0.005]
                  actor_weight_decay:
                    values: [1e-5, 5e-5, 1e-4, 2e-4, 5e-4]
                  critic_weight_decay:
                    values: [1e-5, 5e-5, 1e-4, 2e-4, 5e-4]
                  gamma:
                    values: [0.97, 0.98, 0.99, 0.995, 0.999]
                  tau:
                    values: [0.005, 0.01, 0.02, 0.03]
                  policy_noise:
                    values: [0.1, 0.15, 0.2, 0.25, 0.3]
                  noise_clip:
                    values: [0.3, 0.4, 0.5, 0.6]
                  exploration_noise:
                    values: [0.1, 0.15, 0.2, 0.25, 0.3]
                  exploration_noise_final:
                    values: [0.02, 0.05, 0.08, 0.1]
                  initial_speed:
                    values: [0.5, 0.6, 0.7, 0.8]
          reward:
            parameters:
              params:
                parameters:
                  pressure_distance:
                    values: [0.75, 0.90, 1.05, 1.20]    # baseline ~1.0
                  pressure_timeout:
                    values: [0.30, 0.50, 0.70]          # baseline 0.5
                  pressure_min_speed:
                    values: [0.15, 0.25, 0.35, 0.40]    # baseline 0.25
                  pressure_bonus:
                    values: [0.02, 0.05, 0.08, 0.11]    # baseline 0.025
                  pressure_bonus_interval:
                    values: [4, 6, 8]
                  speed_bonus_coef:
                    values: [0.02, 0.04, 0.06, 0.08]    # baseline 0.05
                  speed_bonus_target:
                    values: [0.40, 0.60, 0.80]          # baseline 0.6
                  distance_reward_near:
                    values: [0.02, 0.04, 0.06]          # baseline 0.04
                  distance_reward_near_distance:
                    values: [0.50, 0.70, 0.90]          # baseline 0.8
