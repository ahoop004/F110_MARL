train episode callback:
[]train/return_attacker,
[]train/steps,
[]train/success,
[]train/epsilon,
[]train/reward_component_{focus_agent}_{name}.

train optimizer updates:
[]train/policy_loss,
[]train/value_loss,
[]train/entropy,
[]train/approx_kl,
[]train/action_mean,
[]train/action_std,
[]train/action_abs_mean,
[]train/raw_action_std,
[]train/value_mean,
[]train/value_std,
[]train/adv_mean,
[]train/adv_std,
[]train/action_histogram,
[]train/value_histogram.

additional aggregation:
[]train/cause.

eval per episode:
[]eval/avg_speed_attacker,
[]eval/avg_speed_defender.

eval summary:
[]eval/success_rate.
