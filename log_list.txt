train episode callback: 
train/episode,
train/return_{agent},
train/return_attacker, 
train/return_defender, 
train/steps, 
train/collisions_total, 
train/success, 
train/defender_crashed, 
train/attacker_crashed, 
train/idle_truncated, 
train/defender_survival_steps, 
train/epsilon, 
train/reward_component_{agent}_{name}.
train optimizer updates: 
train/update, 
train/policy_loss, 
train/value_loss, 
train/entropy, 
train/approx_kl, 
train/action_mean, 
train/action_std, 
train/action_abs_mean, 
train/raw_action_std, 
train/value_mean, 
train/value_std, 
train/adv_mean, 
train/adv_std, 
train/action_histogram, 
train/value_histogram.

Additional per-episode metrics after cleanup: 
train/return_{other_agents}, 
train/collision_count_{agent}, 
train/collision_step_{agent}, 
train/avg_speed_{agent}, 
train/reward_component_{agent}_{name} (non-focus agents), 
train/reward_component_attacker_{name}, 
train/reward_component_defender_{name}, 
train/reward_mode, train/cause.

eval per episode: 
eval/episode, 
eval/steps, 
eval/return_{agent}, 
eval/collision_total, 
eval/collision_count_{agent}, 
eval/collision_step_{agent}, 
eval/lap_count_{agent}, 
eval/avg_speed_{agent}, 
eval/avg_speed_attacker, 
eval/avg_speed_defender, 
eval/defender_crashed, 
eval/attacker_crashed, 
eval/defender_crash_step, 
eval/attacker_crash_step, 
eval/defender_survival_steps.

eval summary: 
eval/success_rate, 
eval/avg_defender_survival_steps.