Defaults to review for federated MARL setup:
- main.federated.enabled: false (scenario opt-in)
- main.federated.interval: 100 episodes fallback (set to 50 in convoy_lock)
- main.federated.agents: [] (must be overridden when enabled)
- main.federated.root: unset (uses cwd if missing)
- main.federated.mode: "mean"
- main.federated.timeout: 600.0 seconds
- main.federated.weights: None (uniform averaging)
- main.federated.checkpoint_after_sync: true
- main.federated.optimizer_strategy: "local"
- run.py FED_* env injection relies on scenario config
- FED_ROUND_INTERVAL env overrides interval when present
- FED_CLIENT_ID / FED_TOTAL_CLIENTS default to 0 / 1 if not provided
- FED_CHECKPOINT_AFTER_SYNC env toggles post-sync checkpointing
- FED_OPTIMIZER_STRATEGY env selects `local`, `average`, or `reset`

Sweepable hyperparameters for `scenarios/convoy_lock_td3.yaml`:
- env.seed: per-run RNG seed (integer). Common choice for sweeps.
- env.max_steps: episode length cap.
- env.terminate_on_any_done: switch for early termination.
- env.vehicle_params.(v_max, v_min, length, width): adjust vehicle dynamics.
- env.spawn_curriculum.*: curriculum thresholds/intervals.
- main.train_episodes: total training episodes per run.
- main.eval_episodes / main.eval_interval: evaluation cadence.
- main.collect_workers / collect_prefetch / collect_seed_stride: parallel collector knobs (future collector feature).
- main.federated.*: interval, optimizer_strategy, root, weights, checkpoint_after_sync.
- agents.car_0.algorithm.name: trainer selection (`td3` here).
- agents.car_0.algorithm.params.actor_lr / critic_lr: learning rates.
- agents.car_0.algorithm.params.gamma / tau: discount and target smoothing.
- agents.car_0.algorithm.params.policy_noise / noise_clip / policy_delay: TD3 exploration schedule.
- agents.car_0.algorithm.params.batch_size / buffer_size / warmup_steps / updates_per_step.
- agents.car_0.algorithm.params.use_per and PER-related parameters (per_alpha, per_beta_start, per_beta, per_beta_increment, per_min_priority, per_epsilon).
- agents.car_0.algorithm.params.exploration_noise / exploration_noise_final / exploration_noise_decay_steps / exploration_noise_decay_episodes.
- agents.car_0.algorithm.params.initial_speed, prevent_reverse*, hidden_dims.
- agents.car_0.reward.params.*: reward shaping (idle penalties, success borders, truncation penalties, etc.).
- agents.car_0.wrappers[0].params.components.* (e.g., lidar beams, pose encodings).
- env.spawn_point_sets / spawn_curriculum variations.

Tips:
- In `grids/*.yaml`, reference nested keys with dot notation (e.g., `agents.car_0.algorithm.params.actor_lr`).
- `runs:` blocks can house bespoke configs if a Cartesian product is too large.
- Combine with `wandb_prefix`/`--wandb-group` for organised dashboards.
