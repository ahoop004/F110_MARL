default_experiment: gaplock_dqn

shared:
  env: &base_env
    seed: 42
    n_agents: 2
    max_steps: 1000
    timestep: 0.01
    integrator: RK4
    render_interval: 0
    vehicle_params:
      v_min: -2.0
      v_max: 10.0
    map_dir: maps
    map_yaml: Shanghai_map.yaml
    map: Shanghai_map.yaml
    map_ext: .png
    render_mode: human
    start_poses:
      - [0.0, 0.0, 0.0]
      - [2.0, 0.1, 0.0]
    start_pose_options:
      -
        - [0.0, 0.0, 0.0]
        - [2.5, 0.1, 0.0]
      -
        - [0.0, 0.0, 0.0]
        - [2.5, -0.1, 0.0]
      -
        - [2.5, 0.1, 0.0]
        - [0.0, 0.0, 0.0]
      -
        - [2.5, -0.1, 0.0]
        - [0.0, 0.0, 0.0]
  defender_policy: &defender_policy
    algo: follow_gap
    slot: 1
    role: defender
    params:
      max_speed: 18.0
      min_speed: 3.0
      steering_gain: 0.85
      bubble_radius: 3
      steer_smooth: 0.35
  reward: &base_reward
    alive_bonus: 0.0
    time_penalty: 0.0
    forward_scale: 0.0021
    reverse_penalty: 0.0040
    lateral_penalty: 0.00025
    target_distance_scale: 0.0015
    target_wall_bonus: 0.0014
    self_wall_penalty: 0.0003
    herd_bonus: 1.2
    ego_collision_penalty: -2.0
    opponent_collision_bonus: 10.0
    target_crash_reward: 100.2
    herd_position_radius: 3.0
    herd_position_slack: 1.2
    herd_position_scale: 0.0028
    herd_angle_scale: 0.0016
    herd_angle_power: 2.0
    slow_speed_threshold: 1.1
    slow_speed_penalty: -0.0022
    progress_threshold: 0.04
    progress_patience: 80
    progress_penalty: 0.0
    spin_thresh: 0.55
    spin_penalty: 1.1
    spin_speed_gate: 0.6
    spin_dwell_steps: 3
    spin_step_cap: 0.0025
    spin_episode_cap: 0.15
    spin_grace_steps: 20
    spin_alpha: 0.2
    dt: 0.01
    p2_enabled: true
    p2_d_back: 0.6
    p2_lat_offset: 0.4
    p2_dist_thresh: 0.3
    p2_angle_align_thresh: 0.35
    p2_blind_angle: 2.356
    p2_hold_decay: 3.0
    p2_distance_scale: 1.0
    p2_angle_scale: 0.5
    p2_blind_bonus: 0.45
    p2_lateral_scale: 0.25
    p2_camp_speed_thresh: 1.5
    p2_camping_penalty: 0.3
    p2_reward_clip: 1.2
    truncation_penalty: -1.0
    idle_speed_threshold: 0.4
    idle_patience_steps: 120
    success_reward_floor: 1.0

experiments:
  gaplock_ppo:
    env:
      <<: *base_env
      update: 10
    agents:
      roster:
        - algo: ppo
          slot: 0
          role: attacker
          config_ref: ppo
          wrappers:
            - factory: obs
              params:
                max_scan: 30.0
                normalize: true
                target_role: defender
        - *defender_policy
    reward: *base_reward
    ppo:
      actor_lr: 0.0003
      critic_lr: 0.0005
      device: cpu
      gamma: 0.99
      lam: 0.95
      ent_coef: 0.015
      ent_coef_schedule:
        start: 0.015
        final: 0.005
        decay_start: 500
        decay_episodes: 1500
      clip_eps: 0.2
      update_epochs: 10
      minibatch_size: 512
      train_episodes: 5000
      eval_episodes: 5
      save_dir: checkpoints
      checkpoint_name: ppo_gaplock.pt
    main:
      mode: train_eval
      wandb:
        enabled: true
        project: marl-f110
        entity: ronnies_group
        group: ppo
        tags: [gaplock, ppo]
      save_eval_rollouts: true
      eval_rollout_dir: eval_rollouts
      checkpoint: checkpoints/ppo_gaplock.pt
      train_episodes: 5000
      eval_episodes: 5

  gaplock_td3:
    env:
      <<: *base_env
      update: 1
    agents:
      roster:
        - algo: td3
          slot: 0
          role: attacker
          config_ref: td3
          wrappers:
            - factory: obs
              params:
                max_scan: 30.0
                normalize: true
                target_role: defender
        - *defender_policy
    reward: *base_reward
    td3:
      actor_lr: 0.0003
      critic_lr: 0.001
      device: cpu
      gamma: 0.99
      tau: 0.005
      policy_noise: 0.3
      noise_clip: 0.5
      policy_delay: 2
      batch_size: 512
      buffer_size: 100000
      warmup_steps: 10000
      exploration_noise: 0.25
      exploration_noise_final: 0.05
      exploration_noise_decay_steps: 250000
      hidden_dims: [256, 256]
      train_episodes: 100
      eval_episodes: 5
      save_dir: checkpoints
      checkpoint_name: td3_gaplock.pt
    main:
      mode: train_eval
      wandb:
        enabled: true
        project: marl-f110
        entity: ronnies_group
        group: td3
        tags: [gaplock, td3]
      save_eval_rollouts: true
      eval_rollout_dir: eval_rollouts
      checkpoint: checkpoints/td3_gaplock.pt
      train_episodes: 5000
      eval_episodes: 5

  gaplock_dqn:
    env:
      <<: *base_env
      update: 2
    agents:
      roster:
        - algo: dqn
          slot: 0
          role: attacker
          config_ref: dqn
          wrappers:
            - factory: obs
              params:
                max_scan: 30.0
                normalize: true
                target_role: defender
        - *defender_policy
    reward: *base_reward
    dqn:
      device: cpu
      lr: 0.0004
      gamma: 0.99
      batch_size: 512
      buffer_size: 100000
      target_update_interval: 500
      epsilon_start: 1.0
      epsilon_end: 0.1
      epsilon_decay_rate: 0.9995
      hidden_dims: [256, 256]
      prioritized_replay: true
      per_alpha: 0.6
      per_beta_start: 0.4
      per_beta_increment: 0.00005
      per_min_priority: 0.001
      per_epsilon: 1.0e-6
      action_set:
        - [-0.50, 2.0]
        - [-0.25, 2.0]
        - [0.0, 2.0]
        - [0.25, 2.0]
        - [0.50, 2.0]
        - [-0.50, 4.0]
        - [-0.25, 4.0]
        - [0.0, 4.0]
        - [0.25, 4.0]
        - [0.50, 4.0]
        - [-0.50, 6.0]
        - [-0.25, 6.0]
        - [0.0, 6.0]
        - [0.25, 6.0]
        - [0.50, 6.0]
        - [-0.50, 8.0]
        - [-0.25, 8.0]
        - [0.0, 8.0]
        - [0.25, 8.0]
        - [0.50, 8.0]
        - [-0.50, 10.0]
        - [-0.25, 10.0]
        - [0.0, 10.0]
        - [0.25, 10.0]
        - [0.50, 10.0]
      train_episodes: 5000
      eval_episodes: 5
      save_dir: checkpoints
      checkpoint_name: dqn_gaplock.pt
    main:
      mode: train_eval
      wandb:
        enabled: true
        project: marl-f110
        entity: ronnies_group
        group: dqn
        tags: [gaplock, dqn]
      save_eval_rollouts: true
      eval_rollout_dir: eval_rollouts
      checkpoint: checkpoints/dqn_gaplock.pt
      train_episodes: 5000
      eval_episodes: 5
