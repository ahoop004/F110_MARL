env:
  seed: 42
  n_agents: 2
  max_steps: 1500
  timestep: 0.01
  integrator: 'RK4'
  render_interval: 0
  update: 1
  vehicle_params:
    v_min: -2.0
    v_max: 8.0

  map_dir: "maps"
  map_yaml: "Shanghai_map.yaml"
  map: 'Shanghai_map.yaml'
  map_ext: .png
  render_mode: 'human'

  start_poses:
    - [0.0, 0.0, 0.0]
    - [3.0, 0.5, 0.0]

agents:
  roster:
    - algo: dqn
      slot: 0
      role: attacker
      config_ref: dqn
      wrappers:
        - factory: obs
          params:
            max_scan: 30.0
            normalize: true
            target_role: defender
    - algo: follow_gap
      slot: 1
      role: defender

reward:
  alive_bonus: 0.1
  forward_scale: 0.12
  reverse_penalty: 0.05
  lateral_penalty: 0.01
  target_distance_scale: 0.25
  target_wall_bonus: 1.5
  self_wall_penalty: 0.2
  herd_bonus: 200.0
  ego_collision_penalty: -80.0
  opponent_collision_bonus: 150.0
  spin_penalty: 1.0
  spin_thresh: 0.4

dqn:
  lr: 0.0005
  gamma: 0.99
  batch_size: 128
  buffer_size: 50000
  target_update_interval: 50
  epsilon_start: 1
  epsilon_end: 0.1
  epsilon_decay_rate: 0.9995
  hidden_dims: [256, 256]
  action_set:
    - [-0.35, 1.5]
    - [-0.15, 2.6]
    - [0.0, 3.2]
    - [0.15, 2.6]
    - [0.35, 1.5]
    - [0.0, 0.0]
  train_episodes: 5000
  eval_episodes: 5
  save_dir: checkpoints/
  checkpoint_name: dqn_gaplock.pt

main:
  mode: train_eval
  wandb:
    enabled: true
    project: marl-f110
    entity: null
    group: dqn
    tags:
      - gaplock
      - dqn
  tensorboard_dir: runs/
  save_eval_rollouts: true
  eval_rollout_dir: eval_rollouts/
  checkpoint: checkpoints/dqn_gaplock.pt
  train_episodes: 5000
  eval_episodes: 5
