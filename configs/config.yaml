env:
  seed: 42
  n_agents: 2
  max_steps: 5000
  timestep: 0.01
  integrator: 'RK4'
  render_interval: 100
  update: 1

  map_dir: "maps"
  map_yaml: "Shanghai_map.yaml"
  map: 'Shanghai_map.yaml'
  map_ext: .png
  render_mode: 'human'
  # TODO: include explicit map_image relative path once assets are standardized, enabling renderer cache priming.



  lidar_beams: 1080
  lidar_range: 30.0
  lidar_dist: 0.0
  start_thresh: 0.5
  vehicle_params:
    mu: 1.0489
    C_Sf: 4.718
    C_Sr: 5.4562
    lf: 0.15875
    lr: 0.17145
    h: 0.074
    m: 3.74
    I: 0.04712
    s_min: -0.4189
    s_max: 0.4189
    sv_min: -3.2
    sv_max: 3.2
    v_switch: 7.319
    a_max: 9.51
    v_min: -5.0
    v_max: 10.0
    width: 0.31
    length: 0.58
  
  start_poses:
    - [0.0, 0.0, 0.0]
    - [2.5, 0.5, 0.0]
  start_pose_options:
    -
      - [0.0, 0.1, 0.0]
      - [2.0, -0.1, 0.0]
    -
      - [0.0, -0.5, 0.0]
      - [2.5, 0.5, 0.0]
    -
      - [0.0, 0.5, 0.0]
      - [3.0, 0.2, 0.0]
    -
      - [0.1, 0.5, 0.0]
      - [3.5, 0.0, 0.0]
    -
      - [3.0, 0.0, 0.0]
      - [2.0, 0.5, 0.0]
    -
      - [0.0, -0.5, 0.0]
      - [2.5, 0.5, 0.0]
    -
      - [0.0, 0.5, 0.0]
      - [3.0, -0.2, 0.0]
    -
      - [0.0, -0.5, 0.0]
      - [3.5, 0.5, 0.0]
  start_pose_back_gap: 3.0
  start_pose_min_spacing: 3.0

mode: "mixed"
ppo_agent_idx: 0   # choose which agent runs PPO
ppo:
  actor_lr: 0.0005
  critic_lr: 0.001
  gamma: 0.99
  lam: 0.95
  ent_coef: 0.01
  clip_eps: 0.2
  update_epochs: 10
  minibatch_size: 64
  train_episodes: 5000
  eval_episodes: 5
  save_dir: checkpoints/
  rolling_avg_window: 10

reward:
  # mode: "pursuit"   # "basic", "pursuit", or "herding"
  alive_bonus: 0.02
  forward_scale: 0.15
  reverse_penalty: 1.5
  lateral_penalty: 0.05
  target_distance_scale: 0.1
  target_wall_bonus: 0.5
  self_wall_penalty: 0.3
  herd_bonus: 250.0
  ego_collision_penalty: -40.0
  spin_penalty: 1.0
  spin_thresh: 0.52   # radians ~30Â°
