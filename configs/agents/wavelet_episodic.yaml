# Wavelet-based Episodic Memory Agent Configuration

agent:
  type: "wavelet_episodic"

  # Observation and action dimensions (will be set by environment)
  obs_dim: 107  # Example for F110 (lidar + pose + velocity)
  act_dim: 2    # steering + velocity

  # Action bounds
  action_low: [-0.4, 0.0]   # [steering_min, velocity_min]
  action_high: [0.4, 8.0]   # [steering_max, velocity_max]

  # Chunk parameters
  chunk_size: 25            # N: 25 timesteps → 5×5 grid
  chunk_stride: 12          # Sliding window stride (~50% overlap)
  grid_shape: [5, 5]        # Spatial arrangement of 25 timesteps
  n_channels: 5             # obs, action, reward, next_obs, done

  # Chronological buffer
  chronological_buffer:
    max_capacity: 10000     # Max transitions before FIFO deletion

  # Episodic buffer
  episodic_buffer:
    capacity: 1000          # Max chunks to store
    selection_mode: "uniform"  # "uniform" or "priority"
    alpha: 0.6              # Priority exponent (for priority mode)
    beta: 0.4               # Importance sampling weight (for priority mode)
    beta_increment: 0.001   # Beta annealing rate

  # Wavelet transform
  wavelet:
    type: "haar"            # "haar", "db2", "db4", "db6", "morlet", "identity"
    mode: "symmetric"       # Padding mode: "symmetric", "zero", "periodic"
    level: null             # Auto-compute based on chunk_size (or specify int)

  # Chunk encoder (CNN-RNN hybrid)
  encoder:
    latent_dim: 128         # Final latent embedding dimension
    cnn:
      channels: [32, 64, 128]     # Conv2D channel progression
      kernel_size: 3              # 3×3 convolutions
      pooling: [2, 2, null]       # MaxPool2D sizes (null = no pooling)
    rnn:
      use: true             # Whether to use RNN after CNN
      type: "rnn"          # "lstm", "gru", or "rnn"
      hidden_size: 256      # RNN hidden dimension
      num_layers: 2         # Number of RNN layers
      dropout: 0.1          # Dropout rate (for num_layers > 1)

  # Multi-task heads
  heads:
    policy_head:
      hidden_dims: [256, 256]
      activation: "relu"
      output_activation: "tanh"  # Tanh for bounded continuous actions

    value_head:
      hidden_dims: [256, 128]

    reconstruction_head:
      hidden_dims: [256, 512]

    forward_head:
      hidden_dims: [256, 512]

  # Loss weights
  loss_weights:
    policy: 1.0            # Policy imitation loss
    value: 0.5             # Value prediction loss
    reconstruction: 0.1    # Chunk reconstruction loss
    forward: 0.1           # Forward model loss

  # Optimization
  learning_rate: 3.0e-4
  batch_size: 32
  max_grad_norm: 1.0

  # Training schedule
  warmup_chunks: 100        # Min chunks before training starts
  update_freq: 4            # Update every N steps

  # Discount factor
  gamma: 0.99

  # Device
  device: "cuda"  # "cuda" or "cpu"

# Example presets for different wavelets
presets:
  haar:
    <<: *agent
    wavelet:
      type: "haar"
      mode: "symmetric"

  daubechies4:
    <<: *agent
    wavelet:
      type: "db4"
      mode: "symmetric"

  morlet:
    <<: *agent
    wavelet:
      type: "morlet"
      scales: [1, 2, 4, 8, 16]
      sampling_period: 1.0

  identity:
    <<: *agent
    wavelet:
      type: "identity"  # No wavelet transform (ablation baseline)
