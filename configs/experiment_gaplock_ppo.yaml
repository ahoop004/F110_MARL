env:
  seed: 42
  n_agents: 2
  max_steps: 2500
  timestep: 0.01
  integrator: 'RK4'
  render_interval: 0
  update: 1
  vehicle_params:
    v_min: -2.0
    v_max: 10.0

  map_dir: "maps"
  map_yaml: "Shanghai_map.yaml"
  map: 'Shanghai_map.yaml'
  map_ext: .png
  render_mode: 'human'

  start_poses:
    - [0.0, 0.0, 0.0]
    - [3.0, 0.5, 0.0]

agents:
  roster:
    - algo: ppo
      slot: 0
      role: attacker
      config_ref: ppo
      wrappers:
        - factory: obs
          params:
            max_scan: 30.0
            normalize: true
            target_role: defender
    - algo: follow_gap
      slot: 1
      role: defender

reward:
  alive_bonus: 0.00007
  forward_scale: 0.002
  reverse_penalty: 0.003
  lateral_penalty: 0.0004
  target_distance_scale: 0.0012
  target_wall_bonus: 0.00004
  self_wall_penalty: 0.00004
  herd_bonus: 0.10
  ego_collision_penalty: -0.30
  opponent_collision_bonus: 0.07
  herd_position_radius: 3.5
  herd_position_slack: 1.0
  herd_position_scale: 0.00006
  herd_angle_scale: 0.00004
  herd_angle_power: 2.0
  slow_speed_threshold: 0.5
  slow_speed_penalty: -0.00008
  spin_thresh: 0.6
  spin_penalty: 0.16
  spin_speed_gate: 0.3
  spin_dwell_steps: 5
  spin_step_cap: 0.00008
  spin_episode_cap: 0.02
  spin_grace_steps: 20
  spin_alpha: 0.2
  dt: 0.01

ppo:
  actor_lr: 0.0003
  critic_lr: 0.0005
  gamma: 0.99
  lam: 0.95
  ent_coef: 0.01
  clip_eps: 0.2
  update_epochs: 2
  minibatch_size: 512
  train_episodes: 5000
  eval_episodes: 5
  save_dir: checkpoints/
  checkpoint_name: ppo_gaplock.pt

main:
  mode: train_eval
  wandb:
    enabled: true
    project: marl-f110
    entity: null
    group: ppo
    tags:
      - gaplock
      - ppo
  tensorboard_dir: runs/
  save_eval_rollouts: true
  eval_rollout_dir: eval_rollouts/
  checkpoint: checkpoints/ppo_gaplock.pt
  train_episodes: 500
  eval_episodes: 5
