{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e56b43e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from torch.serialization import add_safe_globals\n",
    "\n",
    "OBS_DIM = 126\n",
    "ACT_DIM = 2\n",
    "DEFAULT_PPO_DIMS = (512, 256, 128)\n",
    "DEFAULT_SAC_DIMS = (512, 256, 128)\n",
    "DEFAULT_ACTION_SET = np.asarray(\n",
    "    [\n",
    "        [-0.35, 0.90],\n",
    "        [-0.15, 0.80],\n",
    "        [0.00, 0.80],\n",
    "        [0.15, 0.80],\n",
    "        [0.35, 0.90],\n",
    "        [-0.20, 0.30],\n",
    "        [0.00, 0.30],\n",
    "        [0.20, 0.30],\n",
    "        [0.00, 0.00],\n",
    "        [0.00, -0.50],\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "\n",
    "def _register_pickle_safe_globals() -> None:\n",
    "    try:\n",
    "        add_safe_globals([np.core.multiarray._reconstruct])\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "_register_pickle_safe_globals()\n",
    "\n",
    "\n",
    "def make_dummy_state(obs_dim: int = OBS_DIM) -> torch.Tensor:\n",
    "    return torch.zeros(1, obs_dim, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def _infer_ppo_dims(state_dict: dict) -> tuple[int, ...]:\n",
    "    dims = []\n",
    "    layer_idx = 0\n",
    "    while True:\n",
    "        key = f\"body.{layer_idx}.weight\"\n",
    "        weight = state_dict.get(key)\n",
    "        if weight is None:\n",
    "            break\n",
    "        dims.append(int(weight.shape[0]))\n",
    "        layer_idx += 2\n",
    "    return tuple(dims)\n",
    "\n",
    "\n",
    "def _infer_sac_dims(state_dict: dict) -> tuple[tuple[int, ...], int]:\n",
    "    dims = []\n",
    "    layer_idx = 0\n",
    "    while True:\n",
    "        key = f\"net.{layer_idx}.weight\"\n",
    "        weight = state_dict.get(key)\n",
    "        if weight is None:\n",
    "            break\n",
    "        dims.append(int(weight.shape[0]))\n",
    "        layer_idx += 2\n",
    "    if not dims:\n",
    "        raise RuntimeError(\"Unable to infer SAC architecture from checkpoint\")\n",
    "    final_out = dims[-1]\n",
    "    if final_out % 2 != 0:\n",
    "        raise RuntimeError(f\"Unexpected SAC final layer size {final_out}; expected even number for mean/log_std pairs\")\n",
    "    act_dim = final_out // 2\n",
    "    hidden_dims = tuple(dims[:-1])\n",
    "    return hidden_dims, act_dim\n",
    "\n",
    "\n",
    "def load_rainbow_actor(ckpt_path: Path, *, device: str = \"cpu\"):\n",
    "    ckpt = torch.load(str(ckpt_path), map_location=device, weights_only=False)\n",
    "    action_set = np.asarray(ckpt.get(\"action_set\", DEFAULT_ACTION_SET), dtype=np.float32)\n",
    "    obs_dim = int(ckpt.get(\"obs_dim\", OBS_DIM))\n",
    "    atoms = int(ckpt.get(\"atoms\", 51))\n",
    "    v_min = float(ckpt.get(\"v_min\", -50.0))\n",
    "    v_max = float(ckpt.get(\"v_max\", 50.0))\n",
    "    noisy = bool(ckpt.get(\"use_noisy\", True))\n",
    "    sigma0 = float(ckpt.get(\"noisy_sigma0\", 0.4))\n",
    "    model = RainbowQNetwork(\n",
    "        obs_dim,\n",
    "        action_set.shape[0],\n",
    "        hidden_dims=DEFAULT_PPO_DIMS,\n",
    "        atoms=atoms,\n",
    "        v_min=v_min,\n",
    "        v_max=v_max,\n",
    "        noisy=noisy,\n",
    "        sigma0=sigma0,\n",
    "    ).to(device).eval()\n",
    "    model.load_state_dict(ckpt[\"q_net\"], strict=True)\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, NoisyLinear):\n",
    "            module.weight_epsilon.zero_()\n",
    "            module.bias_epsilon.zero_()\n",
    "    return model, action_set, ckpt\n",
    "\n",
    "\n",
    "def load_ppo_actor(ckpt_path: Path, *, device: str = \"cpu\") -> \"PPOActor\":\n",
    "    ckpt = torch.load(str(ckpt_path), map_location=device)\n",
    "    if isinstance(ckpt, nn.Module):\n",
    "        state = ckpt.state_dict()\n",
    "    elif isinstance(ckpt, dict):\n",
    "        actor_state = ckpt.get(\"actor\")\n",
    "        if isinstance(actor_state, dict):\n",
    "            state = actor_state\n",
    "        elif all(isinstance(k, str) for k in ckpt):\n",
    "            state = ckpt\n",
    "        else:\n",
    "            state = None\n",
    "    else:\n",
    "        state = None\n",
    "    if state is None:\n",
    "        raise RuntimeError(f\"Unsupported PPO checkpoint format: keys={list(ckpt.keys())}\")\n",
    "    hidden_dims = _infer_ppo_dims(state) or DEFAULT_PPO_DIMS\n",
    "    actor = PPOActor(hidden_dims=hidden_dims).to(device).eval()\n",
    "    actor.load_state_dict(state, strict=False)\n",
    "    return actor\n",
    "\n",
    "\n",
    "def load_td3_actor(ckpt_path: Path, *, device: str = \"cpu\") -> \"TD3Actor\":\n",
    "    ckpt = torch.load(str(ckpt_path), map_location=device)\n",
    "    state = None\n",
    "    if isinstance(ckpt, nn.Module):\n",
    "        state = ckpt.state_dict()\n",
    "    elif isinstance(ckpt, dict):\n",
    "        for key in (\"actor\", \"policy\", \"model\", \"actor_state_dict\", \"policy_state_dict\"):\n",
    "            payload = ckpt.get(key)\n",
    "            if isinstance(payload, dict):\n",
    "                state = payload\n",
    "                break\n",
    "        if state is None and all(isinstance(k, str) for k in ckpt):\n",
    "            state = ckpt\n",
    "    if state is None:\n",
    "        raise RuntimeError(f\"Unsupported TD3 checkpoint format: keys={list(ckpt.keys())}\")\n",
    "    actor = TD3Actor().to(device).eval()\n",
    "    actor.load_state_dict(state, strict=False)\n",
    "    return actor\n",
    "\n",
    "\n",
    "def load_sac_actor(ckpt_path: Path, *, device: str = \"cpu\") -> \"GaussianPolicy\":\n",
    "    ckpt = torch.load(str(ckpt_path), map_location=device)\n",
    "    actor_state = ckpt.get(\"actor\") if isinstance(ckpt, dict) else None\n",
    "    if not isinstance(actor_state, dict):\n",
    "        raise RuntimeError(f\"Unsupported SAC checkpoint format: keys={list(ckpt.keys())}\")\n",
    "    hidden_dims, act_dim = _infer_sac_dims(actor_state)\n",
    "    policy = GaussianPolicy(hidden_dims=hidden_dims or DEFAULT_SAC_DIMS, act_dim=act_dim).to(device).eval()\n",
    "    policy.load_state_dict(actor_state, strict=True)\n",
    "    return policy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c377b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, sigma0: float = 0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.in_features = int(in_features)\n",
    "        self.out_features = int(out_features)\n",
    "        self.sigma0 = float(sigma0)\n",
    "        weight_shape = (self.out_features, self.in_features)\n",
    "        self.weight_mu = nn.Parameter(torch.empty(weight_shape))\n",
    "        self.weight_sigma = nn.Parameter(torch.empty(weight_shape))\n",
    "        self.register_buffer(\"weight_epsilon\", torch.zeros(weight_shape))\n",
    "        self.bias_mu = nn.Parameter(torch.empty(self.out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.empty(self.out_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.zeros(self.out_features))\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        bound = 1.0 / np.sqrt(self.in_features)\n",
    "        self.weight_mu.data.uniform_(-bound, bound)\n",
    "        self.bias_mu.data.uniform_(-bound, bound)\n",
    "        sigma_weight = self.sigma0 / np.sqrt(self.in_features)\n",
    "        sigma_bias = self.sigma0 / np.sqrt(self.out_features)\n",
    "        self.weight_sigma.data.fill_(sigma_weight)\n",
    "        self.bias_sigma.data.fill_(sigma_bias)\n",
    "\n",
    "    def reset_noise(self) -> None:\n",
    "        eps_in = self._scale_noise(self.in_features, device=self.weight_mu.device)\n",
    "        eps_out = self._scale_noise(self.out_features, device=self.weight_mu.device)\n",
    "        self.weight_epsilon.copy_(torch.outer(eps_out, eps_in))\n",
    "        self.bias_epsilon.copy_(eps_out)\n",
    "\n",
    "    @staticmethod\n",
    "    def _scale_noise(size: int, *, device: torch.device) -> torch.Tensor:\n",
    "        noise = torch.randn(size, device=device)\n",
    "        return noise.sign().mul_(noise.abs().sqrt_())\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        if self.training:\n",
    "            weight = self.weight_mu + self.weight_sigma * self.weight_epsilon\n",
    "            bias = self.bias_mu + self.bias_sigma * self.bias_epsilon\n",
    "        else:\n",
    "            weight = self.weight_mu\n",
    "            bias = self.bias_mu\n",
    "        return F.linear(input, weight, bias)\n",
    "\n",
    "\n",
    "class RainbowQNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        n_actions: int,\n",
    "        hidden_dims=DEFAULT_HIDDEN_DIMS,\n",
    "        *,\n",
    "        atoms: int = 51,\n",
    "        v_min: float = -50.0,\n",
    "        v_max: float = 50.0,\n",
    "        noisy: bool = True,\n",
    "        sigma0: float = 0.4,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.n_actions = int(n_actions)\n",
    "        self.atoms = int(atoms)\n",
    "        self.v_min = float(v_min)\n",
    "        self.v_max = float(v_max)\n",
    "        self.noisy = bool(noisy)\n",
    "        self.sigma0 = float(sigma0)\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self._noisy_layers: list[NoisyLinear] = []\n",
    "        prev = input_dim\n",
    "        for dim in hidden_dims:\n",
    "            layer = self._make_linear(prev, int(dim))\n",
    "            self.hidden_layers.append(layer)\n",
    "            prev = int(dim)\n",
    "        self.value_head = self._make_linear(prev, self.atoms)\n",
    "        self.advantage_head = self._make_linear(prev, self.n_actions * self.atoms)\n",
    "        support = torch.linspace(self.v_min, self.v_max, self.atoms)\n",
    "        self.register_buffer(\"support\", support)\n",
    "\n",
    "    def _make_linear(self, in_dim: int, out_dim: int) -> nn.Module:\n",
    "        if self.noisy:\n",
    "            layer = NoisyLinear(in_dim, out_dim, sigma0=self.sigma0)\n",
    "            self._noisy_layers.append(layer)\n",
    "            return layer\n",
    "        return nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def reset_noise(self) -> None:\n",
    "        if not self.noisy:\n",
    "            return\n",
    "        for layer in self._noisy_layers:\n",
    "            layer.reset_noise()\n",
    "\n",
    "    def forward(self, obs: torch.Tensor) -> torch.Tensor:\n",
    "        x = obs\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "        value = self.value_head(x).view(-1, 1, self.atoms)\n",
    "        adv = self.advantage_head(x).view(-1, self.n_actions, self.atoms)\n",
    "        adv = adv - adv.mean(dim=1, keepdim=True)\n",
    "        return value + adv\n",
    "\n",
    "    def q_values(self, obs: torch.Tensor) -> torch.Tensor:\n",
    "        logits = self.forward(obs)\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        return torch.sum(probs * self.support, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "35b0b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PPOActor(nn.Module):\n",
    "    def __init__(self, obs_dim: int = OBS_DIM, hidden_dims=DEFAULT_PPO_DIMS, act_dim: int = ACT_DIM) -> None:\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = obs_dim\n",
    "        for hid in hidden_dims:\n",
    "            layers.extend([nn.Linear(prev, hid), nn.ReLU()])\n",
    "            prev = hid\n",
    "        self.body = nn.Sequential(*layers)\n",
    "        self.mu_head = nn.Linear(prev, act_dim)\n",
    "        self.log_std = nn.Parameter(torch.zeros(act_dim))\n",
    "\n",
    "    def forward(self, obs: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        features = self.body(obs)\n",
    "        mu = self.mu_head(features)\n",
    "        std = torch.exp(torch.clamp(self.log_std, -5.0, 2.0))\n",
    "        return mu, std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "699d285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TD3Actor(nn.Module):\n",
    "    def __init__(self, obs_dim: int = OBS_DIM, hidden_dims=DEFAULT_HIDDEN_DIMS, act_dim: int = ACT_DIM) -> None:\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = obs_dim\n",
    "        for hid in hidden_dims:\n",
    "            layers.extend([nn.Linear(prev, hid), nn.ReLU()])\n",
    "            prev = hid\n",
    "        layers.append(nn.Linear(prev, act_dim))\n",
    "        layers.append(nn.Tanh())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, obs: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bc685906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GaussianPolicy(nn.Module):\n",
    "    def __init__(self, obs_dim: int = OBS_DIM, hidden_dims=DEFAULT_SAC_DIMS, act_dim: int = ACT_DIM) -> None:\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = obs_dim\n",
    "        for hid in hidden_dims:\n",
    "            layers.extend([nn.Linear(prev, hid), nn.ReLU()])\n",
    "            prev = hid\n",
    "        layers.append(nn.Linear(prev, act_dim * 2))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.act_dim = int(act_dim)\n",
    "\n",
    "    def forward(self, obs: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        raw = self.net(obs)\n",
    "        mu, log_std = torch.split(raw, self.act_dim, dim=-1)\n",
    "        return mu, log_std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "18ce6d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Rainbow Q-network from r_dqn_best_magic-sweep-1.pt\n",
      "Best discrete action index: 1\n",
      "Action (steer, throttle): [-0.15  0.8 ]\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "ckpt_path = Path(\"r_dqn_best_magic-sweep-1.pt\")\n",
    "if not ckpt_path.exists():\n",
    "    print(f\"Rainbow checkpoint missing: {ckpt_path.resolve()}\")\n",
    "else:\n",
    "    q_net, action_set, meta = load_rainbow_actor(ckpt_path, device=device)\n",
    "    obs = make_dummy_state(int(meta.get(\"obs_dim\", OBS_DIM))).to(device)\n",
    "    with torch.no_grad():\n",
    "        q_vals = q_net.q_values(obs)\n",
    "    best_idx = int(q_vals.argmax(dim=1))\n",
    "    print(f\"Loaded Rainbow Q-network from {ckpt_path}\")\n",
    "    print(\"Best discrete action index:\", best_idx)\n",
    "    print(\"Action (steer, throttle):\", action_set[best_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "beca74a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded PPO checkpoint from ppo_best_vague-sweep-1.pt\n",
      "Mean action (tanh-squashed): [ 0.99759793 -0.9907341 ]\n",
      "Std dev: [7.389056 4.357516]\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "ckpt_path = Path(\"ppo_best_vague-sweep-1.pt\")\n",
    "if not ckpt_path.exists():\n",
    "    print(f\"PPO checkpoint missing: {ckpt_path.resolve()}\")\n",
    "else:\n",
    "    actor = load_ppo_actor(ckpt_path, device=device)\n",
    "    obs = make_dummy_state().to(device)\n",
    "    with torch.no_grad():\n",
    "        mu, std = actor(obs)\n",
    "        action = torch.tanh(mu).cpu().numpy()[0]\n",
    "    print(f\"Loaded PPO checkpoint from {ckpt_path}\")\n",
    "    print(\"Mean action (tanh-squashed):\", action)\n",
    "    print(\"Std dev:\", std.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1d561bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded TD3 checkpoint from td3_gaplock_young-sweep-2.pt\n",
      "Action (steer, throttle): [-0.9998891 -0.9999323]\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "ckpt_path = Path(\"td3_gaplock_young-sweep-2.pt\")\n",
    "if not ckpt_path.exists():\n",
    "    print(f\"TD3 checkpoint missing: {ckpt_path.resolve()}\")\n",
    "else:\n",
    "    actor = load_td3_actor(ckpt_path, device=device)\n",
    "    obs = make_dummy_state().to(device)\n",
    "    with torch.no_grad():\n",
    "        action = actor(obs).cpu().numpy()[0]\n",
    "    print(f\"Loaded TD3 checkpoint from {ckpt_path}\")\n",
    "    print(\"Action (steer, throttle):\", action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "43fc6ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SAC checkpoint from sac_best_honest-sweep-1.pt\n",
      "Mean action (tanh-squashed): [-0.9682152  -0.99223673]\n",
      "Log std: [[-0.69195795 -0.8922051 ]]\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "ckpt_path = Path(\"sac_best_honest-sweep-1.pt\")\n",
    "if not ckpt_path.exists():\n",
    "    print(f\"SAC checkpoint missing: {ckpt_path.resolve()}\")\n",
    "else:\n",
    "    policy = load_sac_actor(ckpt_path, device=device)\n",
    "    obs = make_dummy_state().to(device)\n",
    "    with torch.no_grad():\n",
    "        mu, log_std = policy(obs)\n",
    "        action = torch.tanh(mu).cpu().numpy()[0]\n",
    "    print(f\"Loaded SAC checkpoint from {ckpt_path}\")\n",
    "    print(\"Mean action (tanh-squashed):\", action)\n",
    "    print(\"Log std:\", log_std.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae1d9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9647f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e81ba37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
