includes:
- ../configs/env/line2_gaplock.yaml
- ../configs/reward/gaplock_attacker.yaml
- ../configs/agents/ftg_defender.yaml
- ../configs/curriculum/line2_gaplock_phased_full.yaml
- ../configs/evaluation/line2_gaplock_eval_curriculum.yaml
- ../configs/wandb.yaml
experiment:
  name: dqn
  episodes: 1500
  seed: 42
environment:
  action_repeat: 2
  max_steps: 2500
agents:
  car_0:
    role: attacker
    algorithm: sb3_dqn
    target_id: car_1
    params:
      # SB3 DQN parameters (using proven SB3 defaults)
      action_set:
      - - 1.0
        - -0.4
      - - 1.0
        - -0.2
      - - 1.0
        - 0.0
      - - 1.0
        - 0.2
      - - 1.0
        - 0.4
      - - 0.8
        - -0.4
      - - 0.8
        - -0.2
      - - 0.8
        - 0.0
      - - 0.8
        - 0.2
      - - 0.8
        - 0.4
      - - 0.6
        - -0.4
      - - 0.6
        - -0.2
      - - 0.6
        - 0.0
      - - 0.6
        - 0.2
      - - 0.6
        - 0.4
      - - 0.4
        - -0.4
      - - 0.4
        - -0.2
      - - 0.4
        - 0.0
      - - 0.4
        - 0.2
      - - 0.4
        - 0.4
      - - 0.2
        - -0.4
      - - 0.2
        - -0.2
      - - 0.2
        - 0.0
      - - 0.2
        - 0.2
      - - 0.2
        - 0.4
      learning_rate: 0.0003
      gamma: 0.995
      tau: 0.005
      hidden_dims:
      - 256
      - 256
      buffer_size: 1000000
      batch_size: 256
      learning_starts: 1000
      exploration_fraction: 0.1
      exploration_initial_eps: 1.0
      exploration_final_eps: 0.05
      train_freq: 4  # DQN typically trains every 4 steps
      gradient_steps: 1  # Number of gradient steps per training
    observation:
      preset: gaplock
wandb:
  enabled: true
  project: marl-f110
  entity: ahoop004-old-dominion-university
  tags:
  - sb3_dqn
  - dqn
  - comparison
  - gaplock
  notes: SB3 DQN comparison for gaplock adversarial task (discrete actions with epsilon-greedy)
