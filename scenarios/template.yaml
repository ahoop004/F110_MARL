meta:
 name: gaplock_dqn

 wandb:
      enabled: true
      project: marl-f110
      entity: ahoop004-old-dominion-university
      group: dqn
      tags:
      - dqn



scenario:
  
  
  env:
    map: Shanghai_map

    mode: train_eval
    save_eval_rollouts: true
    eval_rollout_dir: eval_rollouts
    checkpoint: checkpoints/dqn_gaplock/dqn_gaplock.pt
    save_dir: checkpoints/dqn_gaplock
    checkpoint_name: dqn_gaplock.pt
    render_mode: human
    
    seed: 42
    max_steps: 10000
    train_episodes: 1000
    eval_episodes: 1
    terminate_on_any_done: true
    randomize_spawm: true

  agents:
    car_0:
      agent_id: car_0
      trainable: true
      algorithm:
        params:
          architecture: dqn
          device: cpu
          lr: 0.0004
          gamma: 0.995
          batch_size: 512
          buffer_size: 200000
          target_update_interval: 500
          epsilon_start: .9980
          epsilon_end: 0.05
          epsilon_decay_rate: 0.996
          net:
            params:
              hidden_dims:
                - 256
                - 256
          memory:
            params:
              prioritized_replay: true
              per_alpha: 0.6
              per_beta_start: 0.4
              per_beta_increment: 5.0e-05
              per_min_priority: 0.001
              per_epsilon: 1.0e-06
      reward:
        params:
          task: gaplock
          # reward_horizon: 500.0
          target_crash_reward: 10.0
          self_collision_penalty: -1.0
          reward_weight: null
          reward_decay: null
          reward_smoothing: null
          relative_reward:
            weights:
              front: 0.0
              front_right: 0.15
              right: 0.1
              back_right: 0.015
              back: -0.01
              back_left: 0.015
              left: 0.1
              front_left: 0.15
            preferred_radius: 0.50
            inner_tolerance: 0.2
            outer_tolerance: 0.2
            # falloff: linear
            # scale: 1.0
      wrappers:
        - factory: act
          params:
            action_mode: rate
            steering_rate: 0.5
            accel_rate: 5.0
            brake_rate: 3.0
            rate_initial_speed: 2.0
        - factory: obs
          params:
            max_scan: 30.0
            normalize: true
            components:
            - id: lidar
              type: lidar
              params:
                beams: 54
                max_range: 30.0
                normalize: true
            - id: ego_pose
              type: ego_pose
              params:
                normalize_xy: 30.0
                angle_mode: sin
            - id: ego_collision
              type: collision
            - id: target_pose
              type: target_pose
              params:
                normalize_xy: 30.0
                angle_mode: sin_cos
              target:
                agent: car_0
            - id: target_collision
              type: collision
              target:
              agent: car_0



    car_1:
      agent_id: car_1
      trainable: false
      
      algorithm:
        params:
          architecture: heuristsic
          
      reward:
        params:
          task: follow_gap
          max_speed: 18.0
          min_speed: 2.0
          steering_gain: 0.95
          bubble_radius: 4
          steer_smooth: 0.0

      wrappers:
      - factory: obs
        params:
          max_scan: 30.0
          normalize: true
          components:
          - id: lidar
            type: lidar
            params:
              beams: 54
              max_range: 30.0
              normalize: true

  
