scenario:
  name: shanghai_centerline_pursuit
  env:
    seed: 0  # RNG seed for reproducibility; change to randomize map sampling and resets
    n_agents: 1  # Number of cars in the sim; add more to race multi-agent
    max_steps: 8000  # Simulation horizon; raise to allow longer laps before truncation
    map_dir: maps  # Root folder for map assets; update if maps live elsewhere
    map_yaml: shanghai/Shanghai_map.yaml  # Specific map file to load; swap to race on another track
    render_mode: human  # Change to null/headless for faster no-render evaluation
    centerline_render: true  # Draw centerline overlay during human rendering for debugging
    centerline_features: true  # Provide centerline-based observations to the agent
    target_laps: 1  # Number of laps to complete before terminating the episode
  reward:
    task: progress  # Use progress-based shaping from src/f110x/tasks/reward/progress.py
    params:
      progress_weight: 2.0  # Reward multiplier for forward progress along the centerline
      speed_weight: 0.0  # Optional bonus for velocity; increase to encourage higher speeds
      lateral_penalty: 0.05  # Penalty on lateral error w.r.t. centerline; raise to hug the center
      heading_penalty: 0.02  # Penalty for heading misalignment; higher discourages aggressive steering
      collision_penalty: -2.0  # Applied when collision flag set; make more negative to punish contact
      truncation_penalty: -1.0  # Penalty when episode ends by step limit instead of success
  main:
    mode: eval  # Run deterministic evaluation; switch to train for learning runs
    eval_episodes: 3  # Number of evaluation rollouts per run; increase for stabler stats
    checkpoint: null  # Path to a saved policy; set to load a trained agent instead of default heuristic
  agents:
    car_0:
      trainable: false  # Heuristic agent; set true only if using a learnable policy wrapper
      algo: centerline  # Uses CenterlinePursuitPolicy from src/f110x/policies/centerline_pursuit.py
      params:
        lookahead_distance: 5.2  # Longer preview so the car eyes deeper into each corner before committing
        base_speed: 3.0  # Cruise speed in m/s before slowdown terms engage
        max_speed: 7.0  # Upper clamp for throttle command; cap for straights while keeping the car stable
        min_speed: 0.8  # Lower clamp to keep the vehicle rolling forward without letting it reverse
        heading_gain: 1.35  # Steering effort toward lookahead heading; balanced for smooth-yet-responsive turning
        lateral_gain: 0.5  # Pull back toward the centerline; tuned to avoid over-biasing toward the inner wall
        turn_slowdown: 4.3  # Speed reduction per radian of heading error to keep rotation controlled
        lookahead_shrink: 0.5  # Gentler adaptive shrink keeps more preview, avoiding premature turn-in
        lateral_speed_gain: 0.5  # Still slows for big cross-track error, but leaves enough pace entering corners
        obstacle_turn_gain: 1.4  # Extra steering bias from LiDAR; pushes away from whichever wall is closest
        obstacle_front_fraction: 0.35  # Portion of beams ahead to monitor for avoidance/slowdown (0â€“1 of the scan span)
        obstacle_speed_gain: 1.5  # Additional speed penalty per meter inside the distance threshold
        obstacle_distance_threshold: 2.2  # Target clearance in meters; when walls are closer, slow down
        lidar_max_range: 30.0  # Physical LiDAR range in meters so the policy can denormalize beam readings
        lidar_normalized: true  # Set false if the observation wrapper already provides raw meter ranges
      wrappers:
        - factory: obs  # Observation wrapper stack; add/remove sensors via components below
          params:
            components:
              - id: lidar
                type: lidar
