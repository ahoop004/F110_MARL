includes:
- ../configs/env/line2_gaplock.yaml
- ../configs/reward/gaplock_attacker.yaml
- ../configs/agents/ftg_defender.yaml
- ../configs/curriculum/line2_gaplock_phased.yaml
- ../configs/evaluation/line2_gaplock_eval_curriculum.yaml
- ../configs/wandb.yaml
experiment:
  name: sac
  episodes: 1500
  seed: 42
environment:
  max_steps: 2500
agents:
  car_0:
    role: attacker
    algorithm: sb3_sac
    target_id: car_1
    params:
      # SB3 SAC parameters (using proven SB3 defaults)
      learning_rate: 0.0003
      gamma: 0.995
      tau: 0.005
      ent_coef: auto  # Automatic entropy tuning
      target_entropy: auto
      hidden_dims:
      - 256
      - 256
      buffer_size: 1000000
      batch_size: 256
      learning_starts: 1000
      train_freq: 1  # Train every step (off-policy continuous)
      gradient_steps: 1  # Number of gradient steps per environment step
    observation:
      preset: gaplock
wandb:
  enabled: true
  project: marl-f110
  entity: ahoop004-old-dominion-university
  tags:
  - improved
  - curriculum_v2
  - sac
  - comparison
  - gaplock
  notes: SAC curriculum for gaplock adversarial task
  mode: online
