meta:
  name: gaplock_td3

scenario:
  env:
    map: line2
    seed: 42
    max_steps: 5000
    lidar_beams: 720
    terminate_on_any_done: true
    vehicle_params:
      v_max: 1.0
      v_min: -1.0
      length: 0.32
      width: 0.225
      s_min: -0.46
      s_max: 0.46
    spawn_points:
      - spawn_2
      - spawn_1
    spawn_cycle: true
    spawn_point_sets:
      - id: attacker_ahead_a
        names: [spawn_3, spawn_1]
      - id: attacker_ahead_b
        names: [spawn_4, spawn_1]
      - id: attacker_far_a
        names: [spawn_5, spawn_2]
      - id: attacker_far_b
        names: [spawn_6, spawn_2]

  main:
    mode: train
    train_episodes: 15000

    checkpoint: checkpoints/td3_gaplock/td3_gaplock.pt
    wandb:
      enabled: true
      project: marl-f110
      entity: ahoop004-old-dominion-university
      group: gaplock_runs
      tags:
        - td3

  agents:
    car_0:
      trainable: true
      role: attacker
      algorithm:
        name: td3
        params:
          device: cuda
          actor_lr: 0.00035
          critic_lr: 0.00035
          actor_optimizer: adamw
          actor_weight_decay: 0.0001
          
          actor_lr_scheduler:
            type: cosine
            t_max: 200000
            eta_min: 0.00002

          critic_lr_scheduler:
            type: step
            step_size: 150000
            gamma: 0.5

          gamma: 0.999
          tau: 0.005
          policy_noise: 0.2
          noise_clip: 0.5
          policy_delay: 2

          batch_size: 256
          buffer_size: 1000000
          warmup_steps: 10000

          updates_per_step: 1
          include_truncation: true

          use_per: true
          per_alpha: 0.6
          per_beta_start: 0.4
          # per_beta: 0.5
          per_beta_final: 1.0
          per_beta_increment: 0.000001
          per_min_priority: 0.00001
          per_epsilon: 0.00001
          exploration_noise: 0.25
          exploration_noise_final: 0.1
          # exploration_noise_decay_steps: 3000000
          exploration_noise_decay_episodes: 1500
          initial_speed: 1.0
          initial_speed_choices:
            - 0.2
            - 0.4
            - 0.5
            - 0.8
            - 1.0
          initial_speed_warmup_steps: 180
          initial_speed_warmup_throttle: 0.5
          prevent_reverse: true
          prevent_reverse_min_speed: 0.01
          prevent_reverse_speed_index: 1
          hidden_dims:
            - 512
            - 256
            - 128

          save_dir: checkpoints/td3_gaplock
          checkpoint_name: td3_gaplock.pt
      reward:
        task: gaplock  # selects which reward logic to use
        ignore_non_trainable: true  # apply shaping only to learning agents
        idle_speed_threshold: 0.0  # speed below this counts as idle
        idle_patience_steps: 0  # steps of idling before truncation
        features:  # named reward presets
          - gaplock_offense  # offense-focused preset
        params:  # gaplock reward tuning knobs
          target_crash_reward: 200.0  # reward for making the target crash
          self_collision_penalty: -220.0  # penalty for crashing yourself

          truncation_penalty: -150.0  # penalty when the episode ends early
          # step_reward: -0.001  # small per-step penalty to encourage progress
          idle_speed_threshold: 0.0  # speed below this counts as idle
          idle_patience_steps: 0  # steps of idling before truncation

          pressure_distance: 0.0  # how close you must be to count as pressure
          pressure_timeout: 0.0  # how long pressure is remembered
          pressure_min_speed: 0.0  # min speed required to count as pressure
          pressure_bonus: 0.0  # bonus for maintaining pressure
          pressure_bonus_interval: 1  # how often the pressure bonus can apply
          success_requires_pressure: false  # only award success if pressure was applied

          speed_bonus_coef: 0.0  # scale for speed-based bonus
          speed_bonus_target: 0.0  # speed where bonus stops increasing

          distance_reward_far_distance: 0.0  # distance where being far starts to matter
          distance_penalty_far: 0.0  # penalty for staying too far away

          # LiDAR wall-proxy bounds for reward computation
          lidar_filter_range_min: 0.15  # ignore lidar hits closer than this
          lidar_filter_range_max: 12.0  # ignore lidar hits farther than this
          target_neighborhood_r_min: 0.40  # inner radius around target to consider
          target_neighborhood_r_max: 6.0  # outer radius around target to consider
          target_neighborhood_x_band: 2.2  # front/back band around target to consider
          target_side_y_epsilon: 0.08  # center band before counting left/right

          # Pinch pocket geometry (new)
          pocket_reward_weight: 0.015  # strength of pocket (pinch) positioning reward
          pinch_anchor_dx: 0.35  # forward offset for the desired pocket
          pinch_anchor_dy: 0.33  # side offset for the desired pocket
          pinch_sigma: 0.4  # spread of the pocket reward
          pinch_in_front_x_min: 0.1  # only reward pocket when in front of target
          pinch_pressure_distance: 1.6  # distance for pinch pressure to count
          pinch_pressure_heading_tol_deg: 35  # heading alignment tolerance
          pinch_pressure_recent_seconds: 1.5  # how long pinch pressure is remembered

          # Potential-field reward (Gaussian, centered on pinch anchors)
          # Set `potential_field_weight` > 0 to enable.
          potential_field_weight: 2.0  # strength of potential-field shaping
          potential_field_sigma: 0.45 # spread of the potential field
          potential_field_peak: 1.0  # max potential-field value
          potential_field_floor: -2.0  # min potential-field value
          potential_field_power: 2.0 # shape of the potential field falloff
          potential_field_time_scaled: true  # scale potential field by timestep

          # Forcing via opposite-side clearance shrink (new)
          force_reward_weight: 10.0  # strength of clearance-shrinking reward
          force_reward_time_scaled: false  # scale clearance reward by timestep
          force_reward_clip: 0.15  # cap clearance reward size
          force_reward_band_min: 0.45  # lower clearance bound for reward
          force_reward_band_max: 3.2  # upper clearance bound for reward
          force_reward_enable_ema: true  # smooth clearance signal over time
          force_reward_ema_alpha: 0.45  # smoothing factor for clearance signal

          # Target yaw-rate hint (new, optional but helpful early)
          turn_reward_weight: 3.0  # strength of target-turning hint
          turn_reward_time_scaled: false  # scale turning hint by timestep
          turn_reward_clip: 0.15  # cap turning hint size


      wrappers:
        - factory: obs
          params:
            max_scan: 12.0
            # normalize: true
            components:
              - id: lidar
                type: lidar
                params:
                  beams: 720
                  max_range: 12.0
                  normalize: true
                  clip: 1.0
              - id: ego_pose
                type: ego_pose
                params:
                  # normalize_xy: 30.0
                  angle_mode: sin_cos
              - id: ego_vel
                type: velocity
                params:
                  normalize: 2.0
                  include_speed: true
                  speed_scale: 1.0
              - id: target_pose
                type: target_pose
                params:
                  # normalize_xy: 30.0
                  angle_mode: sin_cos
                target:
                  agent: car_1
              - id: target_vel
                type: velocity
                params:
                  normalize: 2.0
                  include_speed: true
                  speed_scale: 1.0
                target:
                  agent: car_1
              - id: relative_pose
                type: relative_pose
                params:
                  # normalize_xy: 30.0
                  angle_mode: sin_cos
                target:
                  agent: car_1


    car_1:
      trainable: false
      role: defender
      algorithm:
        name: follow_gap
        params:
          max_distance: 12.0
          window_size: 5
          bubble_radius: 70
          max_steer: 1.0
          min_speed: 0.1
          max_speed: 1.0
          steering_gain: 20.0
          fov_deg: 240
          # target_mode: farthest
          use_disparity_extender: true
          safety_margin: 0.08
          cutback_clearance: 0.9
          cutback_hold_steps: 8
          # gap_min_range: 0.65
          steer_smooth: 0.1
          center_bias_gain: 0.00
          crawl_steer_ratio: 0.35
          steering_speed_scale: 1.0
          preview_horizon: 1.5
          preview_samples: 7
          dwa_samples: 5
          dwa_horizon: 0.5
          dwa_heading_weight: 0.15
          enhanced_gap_scoring: true
          gap_score_width_weight: 1.0
          gap_score_clearance_weight: 1.2
          gap_score_center_weight: 0.5
          gap_score_curvature_weight: 0.2
          u_shape_enabled: false
      # policy_curriculum:
      #   success_window: 40
      #   activation_samples: 30
      #   cooldown: 25
      #   persist: true
      #   stages:
      #     - name: tier0_dumb_defender
      #       params:
      #         max_speed: 0.80
      #         min_speed: 0.35
      #         steering_gain: 0.25
      #         steer_smooth: 0.5
      #         crawl_steer_ratio: 0.55
      #         center_bias_gain: 0.0
      #         inside_bias_gain: 0.0
      #         preview_horizon: 0.0
      #         preview_samples: 0
      #         dwa_samples: 0
      #         enhanced_gap_scoring: false
      #         u_shape_enabled: false
      #     - name: tier1_preview_defender
      #       enable_rate: 0.3
      #       enable_patience: 3
      #       params:
      #         max_speed: 0.80
      #         min_speed: 0.3
      #         steering_gain: 0.32
      #         steer_smooth: 0.42
      #         crawl_steer_ratio: 0.45
      #         center_bias_gain: 0.05
      #         inside_bias_gain: 0.1
      #         preview_horizon: 0.8
      #         preview_samples: 5
      #         dwa_samples: 0
      #         enhanced_gap_scoring: true
      #         dwa_horizon: 0.5
      #         dwa_heading_weight: 0.2
      #         u_shape_enabled: false
      #     - name: tier2_top_defender
      #       enable_rate: 0.55
      #       enable_patience: 4
      #       params:
      #         max_distance: 8.0
      #         window_size: 2
      #         bubble_radius: 1
      #         max_steer: 0.35
      #         min_speed: 0.2
      #         max_speed: 0.80
      #         steering_gain: 0.4
      #         fov_deg: 240
      #         # normalized: true
      #         steer_smooth: 0.35
      #         center_bias_gain: 0.09
      #         inside_bias_gain: 0.2
      #         crawl_steer_ratio: 0.35
      #         steering_speed_scale: 1.0
      #         preview_horizon: 1.5
      #         preview_samples: 7
      #         dwa_samples: 5
      #         dwa_horizon: 0.5
      #         dwa_heading_weight: 0.15
      #         enhanced_gap_scoring: true
      #         gap_score_width_weight: 1.0
      #         gap_score_clearance_weight: 1.2
      #         gap_score_center_weight: 0.5
      #         gap_score_curvature_weight: 0.2
      #         u_shape_enabled: false
