experiment:
  name: gaplock_rainbow_comparison
  episodes: 2500
  seed: 42
  normalize_observations: false
environment:
  map: maps/line2/line2.yaml
  num_agents: 2
  max_steps: 2500
  lidar_beams: 108
  spawn_points:
  - spawn_2
  - spawn_1
  timestep: 0.01
  render: false
  spawn_curriculum:
    enabled: true
    window: 200
    activation_samples: 50
    min_episode: 50
    enable_patience: 5
    disable_patience: 3
    cooldown: 20
    lock_speed_steps: 550
    lock_speed_schedule:
      by_stage:
        optimal_fixed: 550
        optimal_varied_speed: 350
        full_random: 200
    stages:
    - name: optimal_fixed
      spawn_points:
      - spawn_pinch_right
      - spawn_pinch_left
      speed_range:
      - 0.44
      - 0.44
      enable_rate: 0.7
    - name: optimal_varied_speed
      spawn_points:
      - spawn_pinch_right
      - spawn_pinch_left
      - spawn_pinch_ahead
      - spawn_approach_0.0C
      - spawn_approach_0.3L
      - spawn_approach_0.3R
      speed_range:
      - 0.3
      - 1.0
      enable_rate: 0.65
      disable_rate: 0.5
    - name: full_random
      spawn_points: all
      speed_range:
      - 0.3
      - 1.0
      disable_rate: 0.45
    spawn_configs:
      spawn_pinch_right:
        car_0:
        - -45.569
        - -1.0
        - 0.2
        car_1:
        - -46.769
        - -0.7
        - 0.0
      spawn_pinch_left:
        car_0:
        - -45.569
        - -0.4
        - -0.2
        car_1:
        - -46.769
        - -0.7
        - 0.0
      spawn_pinch_ahead:
        car_0:
        - -45.569
        - -0.7
        - 0.0
        car_1:
        - -46.769
        - -0.7
        - 0.0
      spawn_approach_0.0C:
        car_0:
        - -49.269
        - -0.7
        - 0.0
        car_1:
        - -46.769
        - -0.7
        - 0.0
      spawn_approach_0.3L:
        car_0:
        - -49.269
        - -0.4
        - 0.0
        car_1:
        - -46.769
        - -0.7
        - 0.0
      spawn_approach_0.3R:
        car_0:
        - -49.269
        - -1.0
        - 0.0
        car_1:
        - -46.769
        - -0.7
        - 0.0
  visualization:
    reward_ring:
      enabled: false
      preferred_radius: 1.5
    heatmap:
      enabled: false
      extent_m: 6.0
      cell_size_m: 0.25
      alpha: 0.22
      update_frequency: 5
  vehicle_params:
    mu: 1.0489
    C_Sf: 4.718
    C_Sr: 5.4562
    lf: 0.15875
    lr: 0.17145
    h: 0.074
    length: 0.32
    width: 0.225
    m: 3.74
    I: 0.04712
    s_min: -0.46
    s_max: 0.46
    sv_min: -3.2
    sv_max: 3.2
    v_switch: 0.8
    a_max: 2.0
    v_min: -1.0
    v_max: 1.0
agents:
  car_0:
    role: attacker
    algorithm: rainbow
    target_id: car_1
    params:
      action_set:
      - - 1.0
        - 0.0
      - - 1.0
        - 0.3
      - - 1.0
        - -0.3
      - - 0.7
        - 0.0
      - - 0.7
        - 0.3
      - - 0.7
        - -0.3
      - - 0.5
        - 0.0
      - - 0.5
        - 0.3
      - - 0.5
        - -0.3
      lr: 0.0005
      gamma: 0.995
      hidden_dims:
      - 256
      - 256
      buffer_size: 1000000
      success_buffer_size: 200000
      success_buffer_ratio: 0.4
      batch_size: 256
      learning_starts: 2500
      target_update_interval: 1000
      noisy_layers: true
      noisy_sigma0: 0.35
      atoms: 51
      v_min: -150.0
      v_max: 250.0
      n_step: 2
      use_per: true
      per_alpha: 0.5
      epsilon_enabled: false
      max_grad_norm: 0.5
    observation:
      preset: gaplock
    reward:
      preset: gaplock_full
      overrides:
        forcing:
          enabled: true
          pinch_pockets:
            enabled: true
            anchor_forward: 1.2
            anchor_lateral: 0.35
            sigma: 0.55
            weight: 0.004
            peak: 1.0
            floor: -0.5
            power: 2.0
          clearance:
            enabled: true
            weight: 0.003
            band_min: 0.3
            band_max: 3.2
            clip: 0.015
            time_scaled: true
          turn:
            enabled: true
            weight: 0.006
            clip: 0.015
            time_scaled: true
        distance:
          enabled: false
          near_distance: 1.0
          far_distance: 2.5
          reward_near: 0.004
          penalty_far: 0.002
        heading:
          enabled: true
          coefficient: 0.001
        speed:
          enabled: true
          bonus_coef: 0.0005
        step_reward: -0.001
        terminal:
          target_crash: 200.0
          self_crash: -20.0
          timeout: -100.0
          collision: 0.0
  car_1:
    role: defender
    algorithm: ftg
    params:
      max_distance: 12.0
      window_size: 4
      bubble_radius: 3
      max_steer: 0.42
      min_speed: 0.2
      max_speed: 1.0
      steering_gain: 0.35
      fov: 4.71238898
      normalized: false
      steer_smooth: 0.6
      mode: lidar
      gap_min_range: 0.4
      target_mode: center
      wall_avoid_kick: 0.02
      panic_factor_near: 1.0
      panic_factor_very_near: 1.0
      use_disparity_extender: true
      disparity_threshold: 0.35
      vehicle_width: 0.225
      safety_margin: 0.08
      no_cutback_enabled: true
      cutback_clearance: 0.9
      cutback_hold_steps: 8
    ftg_schedule:
      enabled: true
      by_stage:
        optimal_varied_speed:
          max_speed: 0.6
          steering_gain: 0.4
          steer_smooth: 0.4
          bubble_radius: 2.5
          safety_margin: 0.1
          gap_min_range: 0.55
          target_mode: center
          wall_avoid_kick: 0.05
          panic_factor_near: 1.1
          panic_factor_very_near: 1.25
        full_random:
          max_speed: 1.0
          steering_gain: 0.6
          steer_smooth: 0.3
          bubble_radius: 3.0
          safety_margin: 0.15
          gap_min_range: 0.65
          target_mode: farthest
          wall_avoid_kick: 0.12
          panic_factor_near: 1.2
          panic_factor_very_near: 1.4
wandb:
  enabled: true
  project: marl-f110
  entity: ahoop004-old-dominion-university
  tags:
  - rainbow
  - dqn
  - comparison
  - gaplock
  notes: Rainbow DQN comparison for gaplock adversarial task (discrete actions with noisy layers)
