meta:
  name: gaplock_sac

scenario:
  env:
    reward_heatmap:
      enabled: true
      alpha: 0.22
      value_scale: 1.0
      extent_m: 6.0
      cell_size_m: 0.05
    map: line2
    seed: 42
    max_steps: 5000
    lidar_beams: 720
    terminate_on_any_done: true
    vehicle_params:
      v_max: 1.0
      v_min: -1.0
      length: 0.32
      width: 0.225
      s_min: -0.46
      s_max: 0.46
    spawn_points:
      - spawn_2
      - spawn_1
    spawn_cycle: true
    spawn_point_sets:
      - id: attacker_ahead_a
        names: [spawn_3, spawn_1]
      - id: attacker_ahead_b
        names: [spawn_4, spawn_1]
      - id: attacker_far_a
        names: [spawn_5, spawn_2]
      - id: attacker_far_b
        names: [spawn_6, spawn_2]


  main:
    mode: train
    train_episodes: 1500
    checkpoint: checkpoints/sac_gaplock/sac_gaplock.pt
    # warm_start_checkpoint: outputs/checkpoints/sac_best_gaplock_sac-r01-f357d6f9.pt
    wandb:
      enabled: true
      project: marl-f110
      entity: ahoop004-old-dominion-university
      group: gaplock_sac
      tags:
        - sac

  agents:
    car_0:
      trainable: true
      role: attacker
      algorithm:
        name: sac
        params:
          device: cuda
          actor_lr: 0.0005
          critic_lr: 0.0005
          alpha_lr: 0.0005

          gamma: 0.99
          tau: 0.005

          batch_size: 256
          buffer_size: 1000000
          warmup_steps: 5000
          success_buffer_size: 200000
          success_buffer_ratio: 0.25
          
          auto_alpha: true
          target_entropy: -2.0
          hidden_dims:
            - 512
            - 256
            - 128

          exploration_noise: 0.0
          exploration_noise_final: 0.0
          exploration_noise_decay_episodes: 1500
          initial_speed: 1.0
          initial_speed_choices:
            - 0.2
            - 0.4
            - 0.5
            - 0.8
            - 1.0
          initial_speed_warmup_steps: 180
          initial_speed_warmup_throttle: 0.5
          prevent_reverse: true
          prevent_reverse_min_speed: 0.01
          prevent_reverse_speed_index: 1
          include_truncation: true
          time_limit_terminal: false
          use_per: false
          per_alpha: 0.6
          per_beta_start: 0.4
          per_beta_final: 1.0
          per_beta_increment: 1e-6
          per_min_priority: 1e-3
          per_epsilon: 1e-6
      reward:
        task: gaplock  # selects which reward logic to use
        ignore_non_trainable: true  # apply shaping only to learning agents
        idle_speed_threshold: 0.0  # speed below this counts as idle
        idle_patience_steps: 0  # steps of idling before truncation
        features:  # named reward presets
          - gaplock_offense  # offense-focused preset
        params:  # gaplock reward tuning knobs
          target_crash_reward: 60.0  # reward for making the target crash
          self_collision_penalty: -90.0  # penalty for crashing yourself

          truncation_penalty: -20.0  # penalty when the episode ends early
          # step_reward: -0.001  # small per-step penalty to encourage progress
          idle_speed_threshold: 0.0  # speed below this counts as idle
          idle_patience_steps: 0  # steps of idling before truncation

          pressure_distance: 1.3  # how close you must be to count as pressure
          pressure_timeout: 1.2  # how long pressure is remembered
          pressure_min_speed: 0.3  # min speed required to count as pressure
          pressure_heading_tolerance: 1.57  # heading tolerance (radians) for pressure
          pressure_bonus: 0.12  # bonus for maintaining pressure
          pressure_bonus_interval: 5  # how often the pressure bonus can apply
          success_requires_pressure: true  # only award success if pressure was applied

          speed_bonus_coef: 0.05  # scale for speed-based bonus
          speed_bonus_target: 0.6  # speed where bonus stops increasing

          distance_reward_far_distance: 0.0  # distance where being far starts to matter
          distance_penalty_far: 0.0  # penalty for staying too far away

          # LiDAR wall-proxy bounds for reward computation
          lidar_filter_range_min: 0.15  # ignore lidar hits closer than this
          lidar_filter_range_max: 12.0  # ignore lidar hits farther than this
          lidar_fov_radians: 4.1887902047863905  # 240 degrees
          lidar_range_max: 12.0
          target_neighborhood_r_min: 0.40  # inner radius around target to consider
          target_neighborhood_r_max: 6.0  # outer radius around target to consider
          target_neighborhood_x_band: 2.2  # front/back band around target to consider
          target_side_y_epsilon: 0.08  # center band before counting left/right

          # Pinch pocket geometry (new)
          pocket_reward_weight: 0.12  # strength of pocket (pinch) positioning reward
          pinch_anchor_dx: 0.55  # forward offset for the desired pocket
          pinch_anchor_dy: 0.45  # side offset for the desired pocket
          pinch_sigma: 0.35  # spread of the pocket reward
          pinch_in_front_x_min: 0.25  # only reward pocket when in front of target
          pinch_pressure_distance: 0.9  # distance for pinch pressure to count
          pinch_pressure_heading_tol_deg: 35  # heading alignment tolerance
          pinch_pressure_recent_seconds: 1.0  # how long pinch pressure is remembered

          # Potential-field reward (Gaussian, centered on pinch anchors)
          # Set `potential_field_weight` > 0 to enable.
          potential_field_weight: 0.8  # strength of potential-field shaping
          potential_field_sigma: 0.45 # spread of the potential field
          potential_field_peak: 0.6  # max potential-field value
          potential_field_floor: -0.25  # min potential-field value
          potential_field_power: 2.0 # shape of the potential field falloff
          potential_field_time_scaled: false  # scale potential field by timestep

          # Forcing via opposite-side clearance shrink (new)
          force_reward_weight: 6.0  # strength of clearance-shrinking reward
          force_reward_time_scaled: false  # scale clearance reward by timestep
          force_reward_clip: 0.25  # cap clearance reward size
          force_reward_band_min: 0.45  # lower clearance bound for reward
          force_reward_band_max: 3.2  # upper clearance bound for reward
          force_reward_enable_ema: true  # smooth clearance signal over time
          force_reward_ema_alpha: 0.45  # smoothing factor for clearance signal

          # Target yaw-rate hint (new, optional but helpful early)
          turn_reward_weight: 2.0  # strength of target-turning hint
          turn_reward_time_scaled: false  # scale turning hint by timestep
          turn_reward_clip: 0.35  # cap turning hint size




      wrappers:
        - factory: obs
          params:
            max_scan: 12.0
            components:
              - id: lidar
                type: lidar
                params:
                  beams: 720
                  max_range: 12.0
                  normalize: true
                  clip: 1.0
              - id: ego_pose
                type: ego_pose
                params:
                  angle_mode: sin_cos
              - id: ego_vel
                type: velocity
                params:
                  normalize: 2.0
                  include_speed: true
                  speed_scale: 1.0
              - id: target_pose
                type: target_pose
                params:
                  angle_mode: sin_cos
                target:
                  agent: car_1
              - id: target_vel
                type: velocity
                params:
                  normalize: 2.0
                  include_speed: true
                  speed_scale: 1.0
                target:
                  agent: car_1
              - id: relative_pose
                type: relative_pose
                params:
                  angle_mode: sin_cos
                target:
                  agent: car_1

    car_1:
      trainable: false
      role: defender
      algorithm:
        name: follow_gap
        params:
          max_distance: 12.0
          window_size: 5
          bubble_radius: 70
          max_steer: 1.0
          min_speed: 0.1
          max_speed: 1.0
          steering_gain: 20.0
          fov_deg: 240
          # target_mode: farthest
          use_disparity_extender: true
          safety_margin: 0.08
          cutback_clearance: 0.9
          cutback_hold_steps: 8
          # gap_min_range: 0.65
          steer_smooth: 0.1
          center_bias_gain: 0.00
          crawl_steer_ratio: 0.35
          steering_speed_scale: 1.0
          preview_horizon: 1.5
          preview_samples: 7
          dwa_samples: 5
          dwa_horizon: 0.5
          dwa_heading_weight: 0.15
          enhanced_gap_scoring: true
          gap_score_width_weight: 1.0
          gap_score_clearance_weight: 1.2
          gap_score_center_weight: 0.5
          gap_score_curvature_weight: 0.2
          u_shape_enabled: false
