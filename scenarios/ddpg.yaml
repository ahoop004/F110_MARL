includes:
- ../configs/env/line2_gaplock.yaml
- ../configs/reward/gaplock_attacker.yaml
- ../configs/agents/ftg_defender.yaml
- ../configs/curriculum/line2_gaplock_phased.yaml
- ../configs/evaluation/line2_gaplock_eval_curriculum.yaml
- ../configs/wandb.yaml
experiment:
  name: ddpg
  episodes: 1500
  seed: 42
environment:
  max_steps: 2500
agents:
  car_0:
    role: attacker
    algorithm: sb3_ddpg
    target_id: car_1
    params:
      # SB3 DDPG parameters (using proven SB3 defaults)
      learning_rate: 0.0003
      gamma: 0.995
      tau: 0.005
      action_noise_sigma: 0.1  # Action noise for exploration
      hidden_dims:
      - 256
      - 256
      buffer_size: 1000000
      batch_size: 256
      learning_starts: 1000
      train_freq: 1  # Train every step (off-policy continuous)
      gradient_steps: 1  # Number of gradient steps per environment step
    observation:
      preset: gaplock
wandb:
  enabled: true
  project: marl-f110
  entity: ahoop004-old-dominion-university
  tags:
  - ddpg
  - comparison
  - gaplock
  notes: DDPG comparison for gaplock adversarial task (simpler predecessor to TD3)
