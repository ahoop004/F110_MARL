includes:
- ../configs/env/line2_gaplock.yaml
- ../configs/reward/gaplock_attacker.yaml
- ../configs/agents/ftg_defender.yaml
- ../configs/curriculum/line2_gaplock_phased_quick.yaml
- ../configs/evaluation/line2_gaplock_eval_curriculum.yaml
- ../configs/wandb.yaml
experiment:
  name: td3
  episodes: 1500
  seed: 42
environment:
  max_steps: 2500
agents:
  car_0:
    role: attacker
    algorithm: sb3_td3
    target_id: car_1
    params:
      learning_rate: 0.0003
      gamma: 0.995
      tau: 0.005
      hidden_dims:
      - 256
      - 256
      activation: relu
      pi_hidden_dims: null
      qf_hidden_dims: null
      buffer_size: 1000000
      batch_size: 256
      learning_starts: 1000
      train_freq: 1  # Train every step (off-policy continuous)
      gradient_steps: 1  # Number of gradient steps per environment step
      policy_delay: 2
      target_policy_noise: 0.2
      target_noise_clip: 0.5
      action_noise_sigma: 0.1
    observation:
      preset: gaplock
wandb:
  enabled: true
  project: marl-f110
  entity: ahoop004-old-dominion-university
  name: null
  group: null
  job_type: null
  tags:
  - improved
  - curriculum_v2
  - td3
  - comparison
  - gaplock
  notes: SAC curriculum for gaplock adversarial task
  mode: online
